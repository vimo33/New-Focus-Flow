{
  "id": "project-20260212-711527",
  "title": "Focus Flow OS",
  "description": "FOCUS FLOW OS\nProduct Requirements Document\nVersion 1.2 — Full Architecture Integration\nFebruary 2, 2026\nVERSION HISTORY\nVersion\nDate\nChanges\nv1.0\nFeb 2, 2026\nInitial PRD — core architecture, vault, dashboard, 5-phase plan\nv1.1\nFeb 2, 2026\nSecurity hardening — Nate’s analysis, ClawHub ban, security checklist\nv1.2\nFeb 2, 2026\nFull integration — Spec-kit, Auto-Claude, Stitch, Coolify, Beads, mem0, AI Council, Flowise\n\n\nTable of Contents\n\n\n\n1. Executive Summary\nFocus Flow OS is a self-hosted personal operating system that transforms raw intent into organized action through an AI-powered pipeline. It runs entirely on a Hetzner VPS behind Tailscale, with Telegram as the primary input channel and an Obsidian vault as the canonical knowledge base.\nVersion 1.2 integrates the complete idea-to-deployment pipeline: capture ideas via Telegram or Dashboard, validate them through an AI Council (OpenClaw sub-agents, upgradeable to Flowise), generate specifications with GitHub Spec-kit, design UIs with Google Stitch (via Gemini CLI or manual), build autonomously with Auto-Claude, review through the Dashboard, and deploy via Coolify—all on a single VPS.\n1.1 What Changed in v1.2\nAdded 6 new tools to the architecture: Spec-kit, Auto-Claude, Google Stitch, Coolify, Beads, mem0\nDefined AI Council validation using OpenClaw sub-agents (with Flowise as Phase 3 upgrade)\nMapped complete 8-step workflow from idea capture to production deployment\nEstablished dual memory architecture: Beads (per-project) + mem0 (personal OS)\nAuto-Claude runs on Hetzner VPS via Claude Code CLI, eliminating local compute dependency\nCoolify manages Docker deployments on the same Hetzner VPS\nCode repositories live at /srv/projects/{project}/ with GitHub remotes for backup\nDashboard built with Auto-Claude using Focus Flow design reference (React/Tailwind)\n\n2. System Architecture\nAll services run on a single Hetzner VPS, accessible only via Tailscale. No ports are exposed to the public internet. The architecture is organized into four layers: Input, Intelligence, Storage, and Output.\n2.1 Architecture Layers\nLayer\nComponents\nPurpose\nInput Layer\nTelegram Bot, Dashboard UI, Voice (whisper.cpp + Piper)\nCapture raw intent from user\nIntelligence Layer\nOpenClaw, AI Council, Spec-kit, Auto-Claude, Gemini CLI/Stitch\nProcess, validate, spec, design, and build\nMemory Layer\nBeads (per-project), mem0 (personal), Obsidian Vault\nPersistent context across agents and sessions\nOutput Layer\nCoolify, Dashboard, Telegram responses, Vault notes\nDeploy apps, present information, store knowledge\n\n2.2 Service Map (Single VPS)\nService\nBinds To\nPort\nAccess\nDocker?\nOpenClaw Gateway\n127.0.0.1\n18789\nTailscale Serve\nHost (or Docker)\nOpenClaw Control UI\n127.0.0.1\n3000\nTailscale Serve\nSame as Gateway\nFocus Flow Dashboard\n127.0.0.1\n5173\nTailscale Serve\nDocker (Coolify)\nCoolify\n127.0.0.1\n8000\nTailscale Serve\nDocker\nmem0 Service\n127.0.0.1\n8050\nInternal only\nDocker\nQdrant (mem0 vector DB)\n127.0.0.1\n6333\nInternal only\nDocker\nAuto-Claude\nN/A (CLI)\nN/A\nSSH/Tailscale\nHost\nSyncthing\n127.0.0.1\n8384\nTailscale Serve\nHost\n\n2.3 Network Topology\nZero public exposure. Every service binds to 127.0.0.1 (localhost). Tailscale Serve provides HTTPS routing and identity headers for authenticated services. The Telegram bot connects outbound to Telegram’s API—no inbound ports needed. SSH access is Tailscale-only.\nUFW/iptables: DENY all inbound except Tailscale interface\nTailscale Serve: Routes tailnet HTTPS to localhost services\nTailscale identity headers: Primary authentication for Dashboard and Control UI\nPincer audit: Mandatory pre-deploy check that gateway binds to 127.0.0.1, not 0.0.0.0\n\n3. Complete Workflow Pipeline\nThe core value proposition: from raw thought to deployed application, triggered by a Telegram message or Dashboard action. Each step maps to a specific tool.\n3.1 The 8-Step Pipeline\nStep\nAction\nTool\nInput\nOutput\n1. Capture\nUser sends raw intent\nTelegram / Dashboard\nVoice, text, link\nvault/00_inbox/ entry\n2. Classify\nAI categorizes intent\nOpenClaw\nInbox entry\nTask / Idea / Note / Event\n3. Validate\nAI Council evaluates idea\nOpenClaw sub-agents\nIdea from vault/03_ideas/\nApproved / Rejected / Needs Info\n4. Spec\nGenerate detailed specification\nGitHub Spec-kit\nValidated idea\nvault/02_projects/{p}/SPEC.md\n5. Design\nGenerate UI mockups + code\nGemini CLI → Stitch\nSpec + design reference\nvault/02_projects/{p}/designs/\n6. Build\nAutonomous development\nAuto-Claude\nSpec + designs + Beads context\nGit repo at /srv/projects/{p}/\n7. Review\nUser reviews in Dashboard\nDashboard\nBuild artifacts + preview\nApproved / Revision requested\n8. Deploy\nShip to production\nCoolify\nGit repo\nLive app with SSL\n\n3.2 Step 1 — Capture (Telegram + Dashboard)\nUser sends a message to Telegram or types in the Dashboard’s Quick Capture screen. OpenClaw receives it, extracts intent, and writes a structured note to vault/00_inbox/.\nVault entry format: YAML frontmatter (type, source, timestamp, confidence) + raw text + AI-extracted metadata (entities, dates, action verbs).\n3.3 Step 2 — Classify\nOpenClaw classifies the inbox entry into one of four types: Task, Idea, Note, or Event. Classification uses action verb detection, deadline indicators, and content analysis. Items route to the appropriate vault folder:\nTasks → vault/01_daily/ or vault/02_projects/{project}/tasks/\nIdeas → vault/03_ideas/\nNotes → vault/04_notes/\nEvents → vault/05_events/\n3.4 Step 3 — AI Council Validation\nIdeas that could become projects pass through the AI Council—a set of OpenClaw sub-agents that evaluate from different perspectives.\n3.4.1 Council Architecture (Phase 1: OpenClaw Sub-Agents)\nThree sub-agents evaluate each idea independently, then a synthesizer produces a recommendation:\nAgent\nPerspective\nEvaluates\nFeasibility Agent\nTechnical viability\nCan this be built? What’s the complexity? Dependencies?\nAlignment Agent\nPersonal goals\nDoes this align with current priorities and available time?\nImpact Agent\nValue assessment\nWhat’s the ROI? Will this actually get used?\nSynthesizer\nFinal recommendation\nAggregates scores → Approve / Reject / Needs More Info\n\nOutput: Council verdict written to vault/03_ideas/{idea}/COUNCIL_VERDICT.md with per-agent reasoning, scores, and final recommendation. User receives Telegram notification with summary and can approve/override via Dashboard.\n3.4.2 Council Upgrade Path (Phase 3: Flowise)\nWhen workflows become more complex (multi-step validation, external data fetching, conditional branching), migrate the Council to Flowise—a self-hosted visual workflow builder. Flowise provides drag-and-drop orchestration, persistent state, and can call any LLM or API endpoint. This keeps the Council extensible without rewriting OpenClaw configurations.\n3.5 Step 4 — Specification (GitHub Spec-kit)\nOnce an idea is approved, Spec-kit transforms it into a comprehensive, executable specification.\nSpec-kit is GitHub’s Spec-Driven Development toolkit. It uses /speckit.constitution to define project principles, /speckit.specify to generate detailed feature specifications, /speckit.plan for technical implementation plans, and /speckit.tasks to break plans into actionable tasks. Specs become executable artifacts—they don’t just guide code generation, they drive it.\nConstitution: vault/02_projects/{project}/.specify/memory/constitution.md\nSpecs: vault/02_projects/{project}/.specify/specs/\nPlans: vault/02_projects/{project}/.specify/plans/\nTasks: vault/02_projects/{project}/.specify/tasks/\n3.6 Step 5 — Design (Google Stitch via Gemini CLI)\nUI design is generated using Google Stitch, accessed either through the Gemini CLI (automated path) or manually through the Stitch web interface (fallback).\nPrimary path (Gemini CLI): Feed the specification and design reference into Gemini CLI, which can invoke Stitch to generate HTML/CSS or React component code. Output is saved to vault/02_projects/{project}/designs/.\nFallback path (Manual): Paste spec into stitch.withgoogle.com, download generated code, place in project designs/ folder.\nDesign reference: The 10 Focus Flow mockups (Quick Capture, Voice Cockpit, Project Workspace, Inbox Processing, Calendar, Dashboard, Ideas Explorer, Wellbeing Tracker, Projects Management, Item Processing Panel) serve as the canonical design system for Stitch prompts.\n3.7 Step 6 — Build (Claude code agent teams on Hetzner)\nAuto-Claude runs on the Hetzner VPS via Claude Code CLI. It takes the specification, designs, and Beads project context to autonomously build the application.\n3.7.1 Claude code agent team Pipeline\nPhase\nAgent\nWhat It Does\n1. Spec Review\nSpec Agent\nReads .specify/ folder, validates completeness\n2. Planning\nPlanner Agent\nBreaks spec into implementation chunks, decides architecture\n3. Coding\nCoder Agent\nWrites code, commits to git worktree\n4. QA Review\nQA Reviewer\nReviews code against spec, runs tests, flags issues\n5. QA Fix\nQA Fixer\nFixes flagged issues, re-runs validation\n6. User Review\nDashboard notification\nUser approves or requests revisions\n\nSecurity: Claude-code uses built-in security profiles and command allowlisting. Git worktree isolation ensures each feature builds in an isolated branch. The Docker sandbox recommendation from Nate’s analysis applies—Claude runs inside a container with mounted project directory only.\n3.7.2 Setup: Claude Code on Hetzner\nClaude Code CLI authenticated on the server. Setup flow:\nSSH into VPS via Tailscale\nInstall Claude Code CLI (npm install -g @anthropic-ai/claude-code)\nAuthenticate via device code flow (one-time browser auth)\nClone Auto-Claude repo, configure project paths\nAuto-Claude invokes Claude Code for each build phase\n3.8 Step 7 — Review (Dashboard)\nThe Dashboard’s Project Workspace screen shows build progress, diffs, test results, and a preview link. User can approve, request revisions (sent back to Auto-Claude), or reject.\n3.9 Step 8 — Deploy (Coolify)\nCoolify runs on the same Hetzner VPS, managing Docker containers for deployed applications.\nGit push to project repo triggers Coolify build\nCoolify builds Docker image, deploys container\nSSL via Coolify’s built-in Let’s Encrypt integration (or Tailscale for internal-only apps)\nPreview deployments for review, production deployments on approval\n\n4. Memory Architecture\nThree memory systems serve different purposes, ensuring agents always have the right context without token bloat.\n4.1 Three-Layer Memory Model\nLayer\nTool\nScope\nStorage\nUsed By\nWorking Memory\nOpenClaw built-in\nCurrent session\n~/.openclaw/sessions/*.jsonl\nOpenClaw\nProject Memory\nBeads\nPer-project decisions & context\n/srv/projects/{project}/.beads/\nAuto-Claude, Spec-kit\nPersonal Memory\nmem0\nCross-project preferences & facts\nQdrant vector DB + service\nOpenClaw, Dashboard, all agents\nKnowledge Base\nObsidian Vault\nAll structured knowledge\n/srv/vault/\nAll agents, human (Obsidian app)\n\n4.2 Beads (Per-Project Memory)\nBeads is an open-source project memory tool that maintains structured context across coding sessions. Each project gets a .beads/ directory tracking decisions, blockers, progress, and technical context.\nExample Beads entries: “Decided to use Supabase for auth”, “Blocked on WebSocket reconnection logic”, “Next: implement user profile page”, “Architecture: React + Tailwind + Vite”\nLocation: /srv/projects/{project}/.beads/\nWritten by: Auto-Claude during build phases\nRead by: Auto-Claude on session resume, Spec-kit for context\n4.3 mem0 (Personal OS Memory)\nmem0 is a persistent memory layer with hybrid vector + optional graph storage. It captures cross-project preferences, personal facts, and interaction patterns.\nExample mem0 entries: “User prefers React over Vue”, “User’s timezone is CET”, “User approved Sonnet 4.5 for mid-complexity tasks”, “User dislikes verbose logging”\nRuns as: Docker container on VPS (localhost:8050) + Qdrant (localhost:6333)\nMCP integration: Exposed as MCP tool for OpenClaw and other agents\nVault linking: mem0 entries include vault_path metadata pointing to source notes\n4.4 Obsidian Vault (Knowledge Base)\nThe vault is the canonical source of truth—human-readable, tool-agnostic, durable. All agents write to it; mem0 and Beads index from it.\n5. Vault Structure\nPath\nPurpose\nWrite Access\n/srv/vault/00_inbox/\nRaw captures from Telegram/Dashboard\nOpenClaw\n/srv/vault/01_daily/\nDaily notes, plans, recaps\nOpenClaw\n/srv/vault/02_projects/\nProject specs, designs, decisions\nSpec-kit, Stitch output, Auto-Claude\n/srv/vault/03_ideas/\nIdeas + Council verdicts\nOpenClaw, Council agents\n/srv/vault/04_notes/\nReference notes, research\nOpenClaw\n/srv/vault/05_events/\nCalendar events, meetings\nOpenClaw\n/srv/vault/06_system/\nSystem config, logs, security audits\nPreflight scripts, agents\n/srv/vault/_assets/\nImages, audio, attachments\nOpenClaw\n/srv/vault/_templates/\nNote templates for each type\nManual\n\n5.1 Project Folder Structure\nEach project in /srv/vault/02_projects/{project}/ contains:\n.specify/ — Spec-kit output (constitution, specs, plans, tasks)\ndesigns/ — Stitch-generated UI code and screenshots\ndecisions/ — Architecture decisions and tradeoffs\nCOUNCIL_VERDICT.md — AI Council evaluation result\nREADME.md — Project overview and status\nThe actual code lives at /srv/projects/{project}/ (separate from vault) with a GitHub remote for backup. The vault stores knowledge about the project; the repo stores the code.\n\n6. Security Model\nThe security model is informed by Nate’s comprehensive analysis of OpenClaw/Moltbot vulnerabilities and the broader community’s documented failure modes.\n6.1 What We Are NOT Doing (v1)\nNO ClawHub skills — zero moderation, documented supply-chain attacks\nNO public internet exposure — everything behind Tailscale\nNO email/calendar integration in Phase 1 — prompt injection risk too high\nNO unrestricted shell execution — Docker sandbox + safeBins allowlist\nNO auto-execution on untrusted input — all destructive actions require approval\nNO plaintext API keys — environment variables or secrets manager only\n6.2 Security Checklist (Pre-Deploy)\n#\nCheck\nTool\nBlocks Deploy?\n1\nGateway binds to 127.0.0.1 (not 0.0.0.0)\nPincer\nYes\n2\nNo ClawHub skills installed\nManual\nYes\n3\nsafeBins allowlist configured\nPincer\nYes\n4\nTelegram dmPolicy: pairing\nConfig review\nYes\n5\nAuto-Claude security profiles enabled\nConfig review\nYes\n6\nDocker sandbox for exec tools\nConfig review\nYes\n7\nVault permissions: 0640 files, 0750 dirs\nPreflight script\nYes\n8\nAPI keys in env vars (not config files)\nPincer + grep\nYes\n9\nNo services exposed on 0.0.0.0\nss -tlnp check\nYes\n10\nCoolify behind Tailscale (not public)\nConfig review\nYes\n11\nmem0 service on localhost only\nDocker config\nYes\n12\nPincer scan passes\npincer.sh scan\nYes\n13\nOpenClaw security audit passes\nopenclaw security audit --deep\nYes\n\n6.3 Industry Vulnerabilities → Our Mitigations\nDocumented Vulnerability\nOur Mitigation\nExposed instances (0.0.0.0 binding + port forwarding)\nGateway on 127.0.0.1, Tailscale Serve, UFW deny all, Pincer enforces\nLocalhost trust bypass via reverse proxies\nTailscale identity headers, trustedProxies configuration\nClawHub supply chain (zero moderation, fake skills)\nComplete ClawHub ban—no downloaded skills, custom only\nPrompt injection via email/calendar\nNo email/calendar integration in Phase 1\nPlaintext credential storage\nEnvironment variables, never in config files\nUnrestricted shell access\nDocker sandbox, safeBins allowlist, Auto-Claude security profiles\n\n\n7. Model Strategy & Cost Control\nToken costs scale fast in agentic workflows. The strategy is three-tier routing: cheap models for high-frequency tasks, mid-tier for synthesis, premium for deep work.\n7.1 Model Routing\nTier\nUse Case\nRecommended Model\nEst. Cost/Day\nA — Capture/Triage\nClassify, tag, file, quick replies\nClaude Haiku 4.5 or GPT-5 mini\n$0.13–$0.35\nB — Synthesis\nDaily plans, project summaries, Council agents\nClaude Sonnet 4.5 or GPT-5\n$0.63–$1.05\nC — Deep Work\nAuto-Claude builds, complex debugging, architecture\nClaude Opus 4.5\n$1.75 (use sparingly)\n\n7.2 Cost Optimization Levers\nPrompt caching: Anthropic supports cache-hit pricing for repetitive system prompts\nContext compaction: OpenClaw’s built-in compaction reduces token usage over long sessions\nmem0 retrieval: Fetch only relevant memories instead of stuffing full history\nBeads context: Structured project context is more token-efficient than raw chat history\nCouncil agents use Sonnet, not Opus: Evaluation doesn’t need maximum intelligence\n8. Dashboard Screens\nThe Dashboard is a React + Tailwind application built using Auto-Claude, following the Focus Flow design reference. It runs as a Docker container managed by Coolify, accessible via Tailscale Serve.\n8.1 Screen Inventory\n#\nScreen\nPurpose\nKey Features\n1\nDashboard (Home)\nDaily overview + quick actions\nToday’s brief, inbox summary, active projects, wellbeing, approvals queue\n2\nQuick Capture\nFast input with auto-routing\nLarge text area, voice input, auto-classification badge, confidence indicator\n3\nVoice Cockpit\nHands-free interaction\nWaveform visualizer, transcript, suggested actions panel\n4\nInbox Processing\nTriage unprocessed items\nSortable list, batch actions, inline processing\n5\nItem Processing Panel\nDetailed item editing\nClassification tabs, AI insight, project picker, tags\n6\nCalendar & Time Blocking\nSchedule visualization\nWeekly view, drag-to-create, focus blocks, deep work indicator\n7\nProjects Management\nAll projects overview\nProgress bars, vault paths, status badges\n8\nProject Workspace\nSingle project detail\nTasks, notes, activity, related ideas, deadlines\n9\nIdeas Explorer\nIdea pipeline management\nCard grid, status filters, Council verdicts, promote-to-project\n10\nWellbeing Tracker\nHealth & energy monitoring\nMood/energy sliders, sleep/exercise inputs, coach nudges, sparklines\n\n8.2 Design System\nToken\nValue\nUsage\nPrimary\n#137FEC\nButtons, active states, links\nBackground Dark\n#101922\nPage backgrounds\nSurface Dark\n#1C2630\nCards, panels\nBorder Dark\n#2A3B4D\nBorders, dividers\nText Muted\n#92ADC9\nSecondary text\nAccent Teal\n#2DD4BF\nSuccess, wellbeing\nFont\nInter\nAll text\nBorder Radius\n0.75rem (xl)\nCards, buttons\nIcons\nMaterial Symbols Outlined\nNavigation, actions\n\n\n9. Docker Compose Structure\nServices are organized into a single docker-compose.yml with explicit network isolation. All services bind to 127.0.0.1.\n9.1 Core Services\nService\nImage / Build\nVolumes\nDepends On\nopenclaw\nopenclaw/openclaw:latest\n~/.openclaw:/data, /srv/vault:/vault\n—\nmem0-service\nmem0ai/mem0:latest\n—\nqdrant\nqdrant\nqdrant/qdrant:latest\nqdrant-data:/qdrant/storage\n—\ncoolify\ncoollabsio/coolify:latest\n/var/run/docker.sock, coolify-data:/data\n—\ndashboard\nBuilt by Coolify from git\n—\nManaged by Coolify\n\n9.2 Host Services (Not in Docker)\nAuto-Claude + Claude Code CLI: Runs on host (needs direct filesystem + git access)\nSyncthing: Runs on host (needs direct filesystem access for vault sync)\nTailscale: Runs on host (manages network interface)\nSpec-kit: Runs on host via uvx (Python tool, invoked on-demand)\nBeads: Runs on host (file-based, per-project .beads/ directories)\n\n10. Implementation Phases\nPhase 0 — Foundation (Week 1)\nGoal: Secure infrastructure, vault structure, Tailscale-only access.\nVerify Tailscale is running, UFW blocks all non-Tailscale inbound\nCreate vault directory structure at /srv/vault/\nFix Syncthing sync between VPS and Mac\nInstall Pincer, run initial audit\nInstall Docker, Docker Compose\nDeploy Coolify on VPS\nPhase 1 — Capture & Classify (Week 2–3)\nGoal: Telegram → OpenClaw → vault working reliably.\nRestart OpenClaw, configure Telegram bot with dmPolicy: pairing\nConfigure OpenClaw to write to /srv/vault/00_inbox/\nSet up classification rules (Task/Idea/Note/Event routing)\nConfigure model routing: Haiku 4.5 for capture/classify\nRun security checklist, fix all findings\nTest: send 20 messages via Telegram, verify correct vault routing\nPhase 2 — Dashboard MVP + Memory (Week 4–6)\nGoal: Dashboard live behind Tailscale, mem0 running, daily workflows working.\nInstall Claude Code CLI on VPS, authenticate\nSet up Auto-Claude on VPS\nUse Auto-Claude to build Dashboard MVP (Home + Capture + Inbox screens)\nDeploy Dashboard via Coolify\nDeploy mem0 + Qdrant in Docker\nConnect OpenClaw to mem0 via MCP\nSet up daily note writer + morning brief\nInstall whisper.cpp + Piper on Mac for voice loop (optional)\nPhase 3 — AI Council + Spec Pipeline (Week 7–9)\nGoal: Ideas pipeline complete: capture → validate → spec.\nBuild Council sub-agents in OpenClaw (Feasibility, Alignment, Impact, Synthesizer)\nBuild Ideas Explorer and Item Processing screens with Auto-Claude\nInstall Spec-kit (uvx --from git+https://github.com/github/spec-kit.git)\nTest end-to-end: idea → council → approval → spec generation\nSet up Beads for first project\nConsider Flowise installation for complex workflow orchestration\nPhase 4 — Autonomous Build Pipeline (Week 10–12)\nGoal: Full idea-to-deployment pipeline working.\nIntegrate Gemini CLI for Stitch UI generation (or establish manual workflow)\nConfigure Claude-code with Beads context loading\nBuild remaining Dashboard screens (Calendar, Projects, Wellbeing, Voice Cockpit)\nSet up Coolify auto-deploy from git push\nTest end-to-end: idea → council → spec → design → build → deploy\nPhase 5 — Polish & Expand (Week 13+)\nGoal: Refinement, additional integrations, Flowise upgrade.\nMigrate Council to Flowise for visual workflow orchestration\nAdd wellbeing tracking integrations\nExpand voice interaction (STT/TTS on Mac + Telegram voice notes)\nPerformance optimization: prompt caching, context compaction tuning\nConsider additional messaging channels (Discord, Slack)\n\n11. Risks & Mitigations\nRisk\nSeverity\nMitigation\nToken costs spiral in agentic loops\nHigh\nThree-tier model routing, prompt caching, compaction, budget alerts\nAuto-Claude modifies system files\nCritical\nDocker sandbox, safeBins, git worktree isolation, security profiles\nmem0 memory poisoning\nMedium\nGate memory writes through curated functions, not raw agent output\nVault sync conflicts (Syncthing)\nMedium\nConflict resolution rules, one-writer-per-folder principle\nOpenClaw instability after updates\nMedium\nPin versions, test in staging before applying updates\nGoogle Stitch API changes or shutdown\nLow\nFallback to manual design + existing mockups as reference\nSingle VPS = single point of failure\nMedium\nHetzner snapshots, GitHub for code, vault backup via Syncthing\nCouncil sub-agents give bad advice\nLow\nUser always has final approval; Council is advisory only\n\n12. Tool Reference\nTool\nVersion/Source\nLicense\nPurpose in Stack\nOpenClaw\ngithub.com/openclaw/openclaw\nOpen Source\nCore AI assistant, Telegram bot, classification, orchestration\nGitHub Spec-kit\ngithub.com/github/spec-kit\nMIT\nSpec-Driven Development: PRDs, plans, tasks from natural language\nAuto-Claude\ngithub.com/AndyMik90/Auto-Claude\nOpen Source\nAutonomous multi-agent coding: Spec→Plan→Code→QA→Fix\nGoogle Stitch\nstitch.withgoogle.com\nFree (Google Labs)\nAI UI design: text/image → HTML/CSS/React\nCoolify\ncoolify.io\nOpen Source\nSelf-hosted PaaS: Docker deploys, SSL, domains\nBeads\ngithub.com/steveyegge/beads\nMIT\nPer-project memory for coding agents\nmem0\ngithub.com/mem0ai/mem0\nOpen Source\nPersistent personal memory layer (vector + graph)\nTailscale\ntailscale.com\nFreemium\nZero-trust networking, identity headers\nSyncthing\nsyncthing.net\nMPL-2.0\nVault sync between VPS and Mac/iPhone\nPincer\ngithub.com/masbindev/pincer\nOpen Source\nSecurity audit for OpenClaw gateway config\nFlowise\ngithub.com/FlowiseAI/Flowise\nApache 2.0\nFuture: Visual workflow builder for complex Council logic\n\n\n13. Appendix\n13.1 Key File Paths\nPath\nWhat\n/srv/vault/\nObsidian vault root (synced to Mac/iPhone)\n/srv/projects/\nCode repositories root\n/srv/projects/{project}/.beads/\nBeads project memory\n/srv/projects/{project}/.specify/\nSpec-kit output\n~/.openclaw/\nOpenClaw config and session logs\n/opt/pincer/\nPincer security audit tool\n/usr/local/bin/openclaw-preflight\nPre-deploy security gate script\n\n13.2 GitHub Repository\nInfrastructure as code, configuration templates, and documentation live at:\nhttps://github.com/vimo33/focus-flow-os\n13.3 Design Reference\nThe 10 dashboard mockups in design_reference.md define the visual language for all Dashboard screens. Auto-Claude and Google Stitch should reference these when generating UI components.\n\n— End of Document —",
  "status": "active",
  "created_at": "2026-02-12T13:25:11.527Z",
  "updated_at": "2026-02-12T13:46:05.884Z",
  "pipeline": {
    "current_phase": "concept",
    "phases": {
      "concept": {
        "phase": "concept",
        "sub_state": "review",
        "started_at": "2026-02-12T13:25:11.532Z",
        "step": "council_review"
      }
    },
    "run_id": "pipeline-1770902711532-l7ye",
    "updated_at": "2026-02-12T13:46:05.883Z"
  },
  "phase": "concept",
  "concept_thread_id": "thread-20260212-711535",
  "artifacts": {
    "refined_concept": "FOCUS FLOW OS\nProduct Requirements Document\nVersion 1.2 — Full Architecture Integration\nFebruary 2, 2026\nVERSION HISTORY\nVersion\nDate\nChanges\nv1.0\nFeb 2, 2026\nInitial PRD — core architecture, vault, dashboard, 5-phase plan\nv1.1\nFeb 2, 2026\nSecurity hardening — Nate’s analysis, ClawHub ban, security checklist\nv1.2\nFeb 2, 2026\nFull integration — Spec-kit, Auto-Claude, Stitch, Coolify, Beads, mem0, AI Council, Flowise\n\n\nTable of Contents\n\n\n\n1. Executive Summary\nFocus Flow OS is a self-hosted personal operating system that transforms raw intent into organized action through an AI-powered pipeline. It runs entirely on a Hetzner VPS behind Tailscale, with Telegram as the primary input channel and an Obsidian vault as the canonical knowledge base.\nVersion 1.2 integrates the complete idea-to-deployment pipeline: capture ideas via Telegram or Dashboard, validate them through an AI Council (OpenClaw sub-agents, upgradeable to Flowise), generate specifications with GitHub Spec-kit, design UIs with Google Stitch (via Gemini CLI or manual), build autonomously with Auto-Claude, review through the Dashboard, and deploy via Coolify—all on a single VPS.\n1.1 What Changed in v1.2\nAdded 6 new tools to the architecture: Spec-kit, Auto-Claude, Google Stitch, Coolify, Beads, mem0\nDefined AI Council validation using OpenClaw sub-agents (with Flowise as Phase 3 upgrade)\nMapped complete 8-step workflow from idea capture to production deployment\nEstablished dual memory architecture: Beads (per-project) + mem0 (personal OS)\nAuto-Claude runs on Hetzner VPS via Claude Code CLI, eliminating local compute dependency\nCoolify manages Docker deployments on the same Hetzner VPS\nCode repositories live at /srv/projects/{project}/ with GitHub remotes for backup\nDashboard built with Auto-Claude using Focus Flow design reference (React/Tailwind)\n\n2. System Architecture\nAll services run on a single Hetzner VPS, accessible only via Tailscale. No ports are exposed to the public internet. The architecture is organized into four layers: Input, Intelligence, Storage, and Output.\n2.1 Architecture Layers\nLayer\nComponents\nPurpose\nInput Layer\nTelegram Bot, Dashboard UI, Voice (whisper.cpp + Piper)\nCapture raw intent from user\nIntelligence Layer\nOpenClaw, AI Council, Spec-kit, Auto-Claude, Gemini CLI/Stitch\nProcess, validate, spec, design, and build\nMemory Layer\nBeads (per-project), mem0 (personal), Obsidian Vault\nPersistent context across agents and sessions\nOutput Layer\nCoolify, Dashboard, Telegram responses, Vault notes\nDeploy apps, present information, store knowledge\n\n2.2 Service Map (Single VPS)\nService\nBinds To\nPort\nAccess\nDocker?\nOpenClaw Gateway\n127.0.0.1\n18789\nTailscale Serve\nHost (or Docker)\nOpenClaw Control UI\n127.0.0.1\n3000\nTailscale Serve\nSame as Gateway\nFocus Flow Dashboard\n127.0.0.1\n5173\nTailscale Serve\nDocker (Coolify)\nCoolify\n127.0.0.1\n8000\nTailscale Serve\nDocker\nmem0 Service\n127.0.0.1\n8050\nInternal only\nDocker\nQdrant (mem0 vector DB)\n127.0.0.1\n6333\nInternal only\nDocker\nAuto-Claude\nN/A (CLI)\nN/A\nSSH/Tailscale\nHost\nSyncthing\n127.0.0.1\n8384\nTailscale Serve\nHost\n\n2.3 Network Topology\nZero public exposure. Every service binds to 127.0.0.1 (localhost). Tailscale Serve provides HTTPS routing and identity headers for authenticated services. The Telegram bot connects outbound to Telegram’s API—no inbound ports needed. SSH access is Tailscale-only.\nUFW/iptables: DENY all inbound except Tailscale interface\nTailscale Serve: Routes tailnet HTTPS to localhost services\nTailscale identity headers: Primary authentication for Dashboard and Control UI\nPincer audit: Mandatory pre-deploy check that gateway binds to 127.0.0.1, not 0.0.0.0\n\n3. Complete Workflow Pipeline\nThe core value proposition: from raw thought to deployed application, triggered by a Telegram message or Dashboard action. Each step maps to a specific tool.\n3.1 The 8-Step Pipeline\nStep\nAction\nTool\nInput\nOutput\n1. Capture\nUser sends raw intent\nTelegram / Dashboard\nVoice, text, link\nvault/00_inbox/ entry\n2. Classify\nAI categorizes intent\nOpenClaw\nInbox entry\nTask / Idea / Note / Event\n3. Validate\nAI Council evaluates idea\nOpenClaw sub-agents\nIdea from vault/03_ideas/\nApproved / Rejected / Needs Info\n4. Spec\nGenerate detailed specification\nGitHub Spec-kit\nValidated idea\nvault/02_projects/{p}/SPEC.md\n5. Design\nGenerate UI mockups + code\nGemini CLI → Stitch\nSpec + design reference\nvault/02_projects/{p}/designs/\n6. Build\nAutonomous development\nAuto-Claude\nSpec + designs + Beads context\nGit repo at /srv/projects/{p}/\n7. Review\nUser reviews in Dashboard\nDashboard\nBuild artifacts + preview\nApproved / Revision requested\n8. Deploy\nShip to production\nCoolify\nGit repo\nLive app with SSL\n\n3.2 Step 1 — Capture (Telegram + Dashboard)\nUser sends a message to Telegram or types in the Dashboard’s Quick Capture screen. OpenClaw receives it, extracts intent, and writes a structured note to vault/00_inbox/.\nVault entry format: YAML frontmatter (type, source, timestamp, confidence) + raw text + AI-extracted metadata (entities, dates, action verbs).\n3.3 Step 2 — Classify\nOpenClaw classifies the inbox entry into one of four types: Task, Idea, Note, or Event. Classification uses action verb detection, deadline indicators, and content analysis. Items route to the appropriate vault folder:\nTasks → vault/01_daily/ or vault/02_projects/{project}/tasks/\nIdeas → vault/03_ideas/\nNotes → vault/04_notes/\nEvents → vault/05_events/\n3.4 Step 3 — AI Council Validation\nIdeas that could become projects pass through the AI Council—a set of OpenClaw sub-agents that evaluate from different perspectives.\n3.4.1 Council Architecture (Phase 1: OpenClaw Sub-Agents)\nThree sub-agents evaluate each idea independently, then a synthesizer produces a recommendation:\nAgent\nPerspective\nEvaluates\nFeasibility Agent\nTechnical viability\nCan this be built? What’s the complexity? Dependencies?\nAlignment Agent\nPersonal goals\nDoes this align with current priorities and available time?\nImpact Agent\nValue assessment\nWhat’s the ROI? Will this actually get used?\nSynthesizer\nFinal recommendation\nAggregates scores → Approve / Reject / Needs More Info\n\nOutput: Council verdict written to vault/03_ideas/{idea}/COUNCIL_VERDICT.md with per-agent reasoning, scores, and final recommendation. User receives Telegram notification with summary and can approve/override via Dashboard.\n3.4.2 Council Upgrade Path (Phase 3: Flowise)\nWhen workflows become more complex (multi-step validation, external data fetching, conditional branching), migrate the Council to Flowise—a self-hosted visual workflow builder. Flowise provides drag-and-drop orchestration, persistent state, and can call any LLM or API endpoint. This keeps the Council extensible without rewriting OpenClaw configurations.\n3.5 Step 4 — Specification (GitHub Spec-kit)\nOnce an idea is approved, Spec-kit transforms it into a comprehensive, executable specification.\nSpec-kit is GitHub’s Spec-Driven Development toolkit. It uses /speckit.constitution to define project principles, /speckit.specify to generate detailed feature specifications, /speckit.plan for technical implementation plans, and /speckit.tasks to break plans into actionable tasks. Specs become executable artifacts—they don’t just guide code generation, they drive it.\nConstitution: vault/02_projects/{project}/.specify/memory/constitution.md\nSpecs: vault/02_projects/{project}/.specify/specs/\nPlans: vault/02_projects/{project}/.specify/plans/\nTasks: vault/02_projects/{project}/.specify/tasks/\n3.6 Step 5 — Design (Google Stitch via Gemini CLI)\nUI design is generated using Google Stitch, accessed either through the Gemini CLI (automated path) or manually through the Stitch web interface (fallback).\nPrimary path (Gemini CLI): Feed the specification and design reference into Gemini CLI, which can invoke Stitch to generate HTML/CSS or React component code. Output is saved to vault/02_projects/{project}/designs/.\nFallback path (Manual): Paste spec into stitch.withgoogle.com, download generated code, place in project designs/ folder.\nDesign reference: The 10 Focus Flow mockups (Quick Capture, Voice Cockpit, Project Workspace, Inbox Processing, Calendar, Dashboard, Ideas Explorer, Wellbeing Tracker, Projects Management, Item Processing Panel) serve as the canonical design system for Stitch prompts.\n3.7 Step 6 — Build (Claude code agent teams on Hetzner)\nAuto-Claude runs on the Hetzner VPS via Claude Code CLI. It takes the specification, designs, and Beads project context to autonomously build the application.\n3.7.1 Claude code agent team Pipeline\nPhase\nAgent\nWhat It Does\n1. Spec Review\nSpec Agent\nReads .specify/ folder, validates completeness\n2. Planning\nPlanner Agent\nBreaks spec into implementation chunks, decides architecture\n3. Coding\nCoder Agent\nWrites code, commits to git worktree\n4. QA Review\nQA Reviewer\nReviews code against spec, runs tests, flags issues\n5. QA Fix\nQA Fixer\nFixes flagged issues, re-runs validation\n6. User Review\nDashboard notification\nUser approves or requests revisions\n\nSecurity: Claude-code uses built-in security profiles and command allowlisting. Git worktree isolation ensures each feature builds in an isolated branch. The Docker sandbox recommendation from Nate’s analysis applies—Claude runs inside a container with mounted project directory only.\n3.7.2 Setup: Claude Code on Hetzner\nClaude Code CLI authenticated on the server. Setup flow:\nSSH into VPS via Tailscale\nInstall Claude Code CLI (npm install -g @anthropic-ai/claude-code)\nAuthenticate via device code flow (one-time browser auth)\nClone Auto-Claude repo, configure project paths\nAuto-Claude invokes Claude Code for each build phase\n3.8 Step 7 — Review (Dashboard)\nThe Dashboard’s Project Workspace screen shows build progress, diffs, test results, and a preview link. User can approve, request revisions (sent back to Auto-Claude), or reject.\n3.9 Step 8 — Deploy (Coolify)\nCoolify runs on the same Hetzner VPS, managing Docker containers for deployed applications.\nGit push to project repo triggers Coolify build\nCoolify builds Docker image, deploys container\nSSL via Coolify’s built-in Let’s Encrypt integration (or Tailscale for internal-only apps)\nPreview deployments for review, production deployments on approval\n\n4. Memory Architecture\nThree memory systems serve different purposes, ensuring agents always have the right context without token bloat.\n4.1 Three-Layer Memory Model\nLayer\nTool\nScope\nStorage\nUsed By\nWorking Memory\nOpenClaw built-in\nCurrent session\n~/.openclaw/sessions/*.jsonl\nOpenClaw\nProject Memory\nBeads\nPer-project decisions & context\n/srv/projects/{project}/.beads/\nAuto-Claude, Spec-kit\nPersonal Memory\nmem0\nCross-project preferences & facts\nQdrant vector DB + service\nOpenClaw, Dashboard, all agents\nKnowledge Base\nObsidian Vault\nAll structured knowledge\n/srv/vault/\nAll agents, human (Obsidian app)\n\n4.2 Beads (Per-Project Memory)\nBeads is an open-source project memory tool that maintains structured context across coding sessions. Each project gets a .beads/ directory tracking decisions, blockers, progress, and technical context.\nExample Beads entries: “Decided to use Supabase for auth”, “Blocked on WebSocket reconnection logic”, “Next: implement user profile page”, “Architecture: React + Tailwind + Vite”\nLocation: /srv/projects/{project}/.beads/\nWritten by: Auto-Claude during build phases\nRead by: Auto-Claude on session resume, Spec-kit for context\n4.3 mem0 (Personal OS Memory)\nmem0 is a persistent memory layer with hybrid vector + optional graph storage. It captures cross-project preferences, personal facts, and interaction patterns.\nExample mem0 entries: “User prefers React over Vue”, “User’s timezone is CET”, “User approved Sonnet 4.5 for mid-complexity tasks”, “User dislikes verbose logging”\nRuns as: Docker container on VPS (localhost:8050) + Qdrant (localhost:6333)\nMCP integration: Exposed as MCP tool for OpenClaw and other agents\nVault linking: mem0 entries include vault_path metadata pointing to source notes\n4.4 Obsidian Vault (Knowledge Base)\nThe vault is the canonical source of truth—human-readable, tool-agnostic, durable. All agents write to it; mem0 and Beads index from it.\n5. Vault Structure\nPath\nPurpose\nWrite Access\n/srv/vault/00_inbox/\nRaw captures from Telegram/Dashboard\nOpenClaw\n/srv/vault/01_daily/\nDaily notes, plans, recaps\nOpenClaw\n/srv/vault/02_projects/\nProject specs, designs, decisions\nSpec-kit, Stitch output, Auto-Claude\n/srv/vault/03_ideas/\nIdeas + Council verdicts\nOpenClaw, Council agents\n/srv/vault/04_notes/\nReference notes, research\nOpenClaw\n/srv/vault/05_events/\nCalendar events, meetings\nOpenClaw\n/srv/vault/06_system/\nSystem config, logs, security audits\nPreflight scripts, agents\n/srv/vault/_assets/\nImages, audio, attachments\nOpenClaw\n/srv/vault/_templates/\nNote templates for each type\nManual\n\n5.1 Project Folder Structure\nEach project in /srv/vault/02_projects/{project}/ contains:\n.specify/ — Spec-kit output (constitution, specs, plans, tasks)\ndesigns/ — Stitch-generated UI code and screenshots\ndecisions/ — Architecture decisions and tradeoffs\nCOUNCIL_VERDICT.md — AI Council evaluation result\nREADME.md — Project overview and status\nThe actual code lives at /srv/projects/{project}/ (separate from vault) with a GitHub remote for backup. The vault stores knowledge about the project; the repo stores the code.\n\n6. Security Model\nThe security model is informed by Nate’s comprehensive analysis of OpenClaw/Moltbot vulnerabilities and the broader community’s documented failure modes.\n6.1 What We Are NOT Doing (v1)\nNO ClawHub skills — zero moderation, documented supply-chain attacks\nNO public internet exposure — everything behind Tailscale\nNO email/calendar integration in Phase 1 — prompt injection risk too high\nNO unrestricted shell execution — Docker sandbox + safeBins allowlist\nNO auto-execution on untrusted input — all destructive actions require approval\nNO plaintext API keys — environment variables or secrets manager only\n6.2 Security Checklist (Pre-Deploy)\n#\nCheck\nTool\nBlocks Deploy?\n1\nGateway binds to 127.0.0.1 (not 0.0.0.0)\nPincer\nYes\n2\nNo ClawHub skills installed\nManual\nYes\n3\nsafeBins allowlist configured\nPincer\nYes\n4\nTelegram dmPolicy: pairing\nConfig review\nYes\n5\nAuto-Claude security profiles enabled\nConfig review\nYes\n6\nDocker sandbox for exec tools\nConfig review\nYes\n7\nVault permissions: 0640 files, 0750 dirs\nPreflight script\nYes\n8\nAPI keys in env vars (not config files)\nPincer + grep\nYes\n9\nNo services exposed on 0.0.0.0\nss -tlnp check\nYes\n10\nCoolify behind Tailscale (not public)\nConfig review\nYes\n11\nmem0 service on localhost only\nDocker config\nYes\n12\nPincer scan passes\npincer.sh scan\nYes\n13\nOpenClaw security audit passes\nopenclaw security audit --deep\nYes\n\n6.3 Industry Vulnerabilities → Our Mitigations\nDocumented Vulnerability\nOur Mitigation\nExposed instances (0.0.0.0 binding + port forwarding)\nGateway on 127.0.0.1, Tailscale Serve, UFW deny all, Pincer enforces\nLocalhost trust bypass via reverse proxies\nTailscale identity headers, trustedProxies configuration\nClawHub supply chain (zero moderation, fake skills)\nComplete ClawHub ban—no downloaded skills, custom only\nPrompt injection via email/calendar\nNo email/calendar integration in Phase 1\nPlaintext credential storage\nEnvironment variables, never in config files\nUnrestricted shell access\nDocker sandbox, safeBins allowlist, Auto-Claude security profiles\n\n\n7. Model Strategy & Cost Control\nToken costs scale fast in agentic workflows. The strategy is three-tier routing: cheap models for high-frequency tasks, mid-tier for synthesis, premium for deep work.\n7.1 Model Routing\nTier\nUse Case\nRecommended Model\nEst. Cost/Day\nA — Capture/Triage\nClassify, tag, file, quick replies\nClaude Haiku 4.5 or GPT-5 mini\n$0.13–$0.35\nB — Synthesis\nDaily plans, project summaries, Council agents\nClaude Sonnet 4.5 or GPT-5\n$0.63–$1.05\nC — Deep Work\nAuto-Claude builds, complex debugging, architecture\nClaude Opus 4.5\n$1.75 (use sparingly)\n\n7.2 Cost Optimization Levers\nPrompt caching: Anthropic supports cache-hit pricing for repetitive system prompts\nContext compaction: OpenClaw’s built-in compaction reduces token usage over long sessions\nmem0 retrieval: Fetch only relevant memories instead of stuffing full history\nBeads context: Structured project context is more token-efficient than raw chat history\nCouncil agents use Sonnet, not Opus: Evaluation doesn’t need maximum intelligence\n8. Dashboard Screens\nThe Dashboard is a React + Tailwind application built using Auto-Claude, following the Focus Flow design reference. It runs as a Docker container managed by Coolify, accessible via Tailscale Serve.\n8.1 Screen Inventory\n#\nScreen\nPurpose\nKey Features\n1\nDashboard (Home)\nDaily overview + quick actions\nToday’s brief, inbox summary, active projects, wellbeing, approvals queue\n2\nQuick Capture\nFast input with auto-routing\nLarge text area, voice input, auto-classification badge, confidence indicator\n3\nVoice Cockpit\nHands-free interaction\nWaveform visualizer, transcript, suggested actions panel\n4\nInbox Processing\nTriage unprocessed items\nSortable list, batch actions, inline processing\n5\nItem Processing Panel\nDetailed item editing\nClassification tabs, AI insight, project picker, tags\n6\nCalendar & Time Blocking\nSchedule visualization\nWeekly view, drag-to-create, focus blocks, deep work indicator\n7\nProjects Management\nAll projects overview\nProgress bars, vault paths, status badges\n8\nProject Workspace\nSingle project detail\nTasks, notes, activity, related ideas, deadlines\n9\nIdeas Explorer\nIdea pipeline management\nCard grid, status filters, Council verdicts, promote-to-project\n10\nWellbeing Tracker\nHealth & energy monitoring\nMood/energy sliders, sleep/exercise inputs, coach nudges, sparklines\n\n8.2 Design System\nToken\nValue\nUsage\nPrimary\n#137FEC\nButtons, active states, links\nBackground Dark\n#101922\nPage backgrounds\nSurface Dark\n#1C2630\nCards, panels\nBorder Dark\n#2A3B4D\nBorders, dividers\nText Muted\n#92ADC9\nSecondary text\nAccent Teal\n#2DD4BF\nSuccess, wellbeing\nFont\nInter\nAll text\nBorder Radius\n0.75rem (xl)\nCards, buttons\nIcons\nMaterial Symbols Outlined\nNavigation, actions\n\n\n9. Docker Compose Structure\nServices are organized into a single docker-compose.yml with explicit network isolation. All services bind to 127.0.0.1.\n9.1 Core Services\nService\nImage / Build\nVolumes\nDepends On\nopenclaw\nopenclaw/openclaw:latest\n~/.openclaw:/data, /srv/vault:/vault\n—\nmem0-service\nmem0ai/mem0:latest\n—\nqdrant\nqdrant\nqdrant/qdrant:latest\nqdrant-data:/qdrant/storage\n—\ncoolify\ncoollabsio/coolify:latest\n/var/run/docker.sock, coolify-data:/data\n—\ndashboard\nBuilt by Coolify from git\n—\nManaged by Coolify\n\n9.2 Host Services (Not in Docker)\nAuto-Claude + Claude Code CLI: Runs on host (needs direct filesystem + git access)\nSyncthing: Runs on host (needs direct filesystem access for vault sync)\nTailscale: Runs on host (manages network interface)\nSpec-kit: Runs on host via uvx (Python tool, invoked on-demand)\nBeads: Runs on host (file-based, per-project .beads/ directories)\n\n10. Implementation Phases\nPhase 0 — Foundation (Week 1)\nGoal: Secure infrastructure, vault structure, Tailscale-only access.\nVerify Tailscale is running, UFW blocks all non-Tailscale inbound\nCreate vault directory structure at /srv/vault/\nFix Syncthing sync between VPS and Mac\nInstall Pincer, run initial audit\nInstall Docker, Docker Compose\nDeploy Coolify on VPS\nPhase 1 — Capture & Classify (Week 2–3)\nGoal: Telegram → OpenClaw → vault working reliably.\nRestart OpenClaw, configure Telegram bot with dmPolicy: pairing\nConfigure OpenClaw to write to /srv/vault/00_inbox/\nSet up classification rules (Task/Idea/Note/Event routing)\nConfigure model routing: Haiku 4.5 for capture/classify\nRun security checklist, fix all findings\nTest: send 20 messages via Telegram, verify correct vault routing\nPhase 2 — Dashboard MVP + Memory (Week 4–6)\nGoal: Dashboard live behind Tailscale, mem0 running, daily workflows working.\nInstall Claude Code CLI on VPS, authenticate\nSet up Auto-Claude on VPS\nUse Auto-Claude to build Dashboard MVP (Home + Capture + Inbox screens)\nDeploy Dashboard via Coolify\nDeploy mem0 + Qdrant in Docker\nConnect OpenClaw to mem0 via MCP\nSet up daily note writer + morning brief\nInstall whisper.cpp + Piper on Mac for voice loop (optional)\nPhase 3 — AI Council + Spec Pipeline (Week 7–9)\nGoal: Ideas pipeline complete: capture → validate → spec.\nBuild Council sub-agents in OpenClaw (Feasibility, Alignment, Impact, Synthesizer)\nBuild Ideas Explorer and Item Processing screens with Auto-Claude\nInstall Spec-kit (uvx --from git+https://github.com/github/spec-kit.git)\nTest end-to-end: idea → council → approval → spec generation\nSet up Beads for first project\nConsider Flowise installation for complex workflow orchestration\nPhase 4 — Autonomous Build Pipeline (Week 10–12)\nGoal: Full idea-to-deployment pipeline working.\nIntegrate Gemini CLI for Stitch UI generation (or establish manual workflow)\nConfigure Claude-code with Beads context loading\nBuild remaining Dashboard screens (Calendar, Projects, Wellbeing, Voice Cockpit)\nSet up Coolify auto-deploy from git push\nTest end-to-end: idea → council → spec → design → build → deploy\nPhase 5 — Polish & Expand (Week 13+)\nGoal: Refinement, additional integrations, Flowise upgrade.\nMigrate Council to Flowise for visual workflow orchestration\nAdd wellbeing tracking integrations\nExpand voice interaction (STT/TTS on Mac + Telegram voice notes)\nPerformance optimization: prompt caching, context compaction tuning\nConsider additional messaging channels (Discord, Slack)\n\n11. Risks & Mitigations\nRisk\nSeverity\nMitigation\nToken costs spiral in agentic loops\nHigh\nThree-tier model routing, prompt caching, compaction, budget alerts\nAuto-Claude modifies system files\nCritical\nDocker sandbox, safeBins, git worktree isolation, security profiles\nmem0 memory poisoning\nMedium\nGate memory writes through curated functions, not raw agent output\nVault sync conflicts (Syncthing)\nMedium\nConflict resolution rules, one-writer-per-folder principle\nOpenClaw instability after updates\nMedium\nPin versions, test in staging before applying updates\nGoogle Stitch API changes or shutdown\nLow\nFallback to manual design + existing mockups as reference\nSingle VPS = single point of failure\nMedium\nHetzner snapshots, GitHub for code, vault backup via Syncthing\nCouncil sub-agents give bad advice\nLow\nUser always has final approval; Council is advisory only\n\n12. Tool Reference\nTool\nVersion/Source\nLicense\nPurpose in Stack\nOpenClaw\ngithub.com/openclaw/openclaw\nOpen Source\nCore AI assistant, Telegram bot, classification, orchestration\nGitHub Spec-kit\ngithub.com/github/spec-kit\nMIT\nSpec-Driven Development: PRDs, plans, tasks from natural language\nAuto-Claude\ngithub.com/AndyMik90/Auto-Claude\nOpen Source\nAutonomous multi-agent coding: Spec→Plan→Code→QA→Fix\nGoogle Stitch\nstitch.withgoogle.com\nFree (Google Labs)\nAI UI design: text/image → HTML/CSS/React\nCoolify\ncoolify.io\nOpen Source\nSelf-hosted PaaS: Docker deploys, SSL, domains\nBeads\ngithub.com/steveyegge/beads\nMIT\nPer-project memory for coding agents\nmem0\ngithub.com/mem0ai/mem0\nOpen Source\nPersistent personal memory layer (vector + graph)\nTailscale\ntailscale.com\nFreemium\nZero-trust networking, identity headers\nSyncthing\nsyncthing.net\nMPL-2.0\nVault sync between VPS and Mac/iPhone\nPincer\ngithub.com/masbindev/pincer\nOpen Source\nSecurity audit for OpenClaw gateway config\nFlowise\ngithub.com/FlowiseAI/Flowise\nApache 2.0\nFuture: Visual workflow builder for complex Council logic\n\n\n13. Appendix\n13.1 Key File Paths\nPath\nWhat\n/srv/vault/\nObsidian vault root (synced to Mac/iPhone)\n/srv/projects/\nCode repositories root\n/srv/projects/{project}/.beads/\nBeads project memory\n/srv/projects/{project}/.specify/\nSpec-kit output\n~/.openclaw/\nOpenClaw config and session logs\n/opt/pincer/\nPincer security audit tool\n/usr/local/bin/openclaw-preflight\nPre-deploy security gate script\n\n13.2 GitHub Repository\nInfrastructure as code, configuration templates, and documentation live at:\nhttps://github.com/vimo33/focus-flow-os\n13.3 Design Reference\nThe 10 dashboard mockups in design_reference.md define the visual language for all Dashboard screens. Auto-Claude and Google Stitch should reference these when generating UI components.\n\n— End of Document —",
    "selected_council": [
      {
        "agent_name": "Self-Hosting Infrastructure Agent",
        "role": "Single-VPS Architecture & Reliability",
        "focus": "Evaluates the viability of running this entire AI orchestration pipeline on a single Hetzner VPS. Assesses resource constraints (CPU/RAM/disk for OpenClaw + Auto-Claude + mem0 + Coolify + Qdrant), backup/disaster recovery strategy, single-point-of-failure risks, and long-term maintenance burden for a personal system.",
        "evaluation_criteria": [
          "Resource adequacy (concurrent AI agents, vector DB, Docker containers on one VPS)",
          "Backup & disaster recovery strategy (Obsidian vault, project repos, mem0 state)",
          "Operational complexity (service dependencies, upgrade paths, debugging)",
          "Cost-to-benefit ratio (Hetzner VPS pricing vs cloud alternatives)",
          "Failover & redundancy (what breaks if VPS goes down)"
        ]
      },
      {
        "agent_name": "AI Orchestration & Cost Agent",
        "role": "Multi-Agent Coordination & Economics",
        "focus": "Evaluates the sustainability of the AI Council + Auto-Claude + Gemini CLI workflow. Assesses API costs at scale (multiple Claude calls per idea, autonomous coding sessions), context window management across Beads + mem0, vendor lock-in to Anthropic/Google, and whether the AI complexity matches the personal productivity use case.",
        "evaluation_criteria": [
          "Monthly API cost projections (AI Council validations, Auto-Claude builds, Gemini UI generation)",
          "Context management efficiency (Beads per-project + mem0 personal overlap/redundancy)",
          "Vendor dependency risk (Anthropic rate limits, API changes, pricing shifts)",
          "Diminishing returns threshold (when does AI orchestration overhead exceed value)",
          "Fallback strategies (degraded operation if AI services unavailable)"
        ]
      },
      {
        "agent_name": "Autonomous Development Safety Agent",
        "role": "Code Generation & Deployment Risk",
        "focus": "Evaluates the risks of Auto-Claude autonomously writing code and Coolify deploying it to production with minimal human review. Assesses potential for insecure code, credential leaks, resource abuse, unintended Telegram bot behaviors, and the adequacy of the review step in the 8-stage pipeline.",
        "evaluation_criteria": [
          "Code safety guardrails (static analysis, secret scanning, Auto-Claude constraints)",
          "Human review bottleneck (can user meaningfully audit Auto-Claude output)",
          "Deployment rollback mechanisms (Coolify rollback, Git history, state recovery)",
          "Blast radius containment (what's the worst an auto-deployed app could do)",
          "Testing & validation strategy (pre-deployment checks, staging environments)"
        ]
      },
      {
        "agent_name": "Personal Workflow Adoption Agent",
        "role": "User Experience & Cognitive Load",
        "focus": "Evaluates whether the 8-step pipeline (Telegram → classify → AI Council → spec → design → build → review → deploy) creates too much friction or notification fatigue for personal use. Assesses learning curve, decision fatigue (AI Council recommendations), Dashboard UX, and whether Obsidian vault + Telegram dual interfaces fragment attention.",
        "evaluation_criteria": [
          "Onboarding complexity (initial setup, learning the pipeline, debugging first failures)",
          "Daily friction points (Telegram notification volume, Dashboard context switching)",
          "Decision fatigue (AI Council recommendations vs user override, review step burden)",
          "Vault organization maintenance (will vault/00_inbox/ become a junk drawer)",
          "Value activation time (how long until first successful idea → deployed app)"
        ]
      },
      {
        "agent_name": "Network Security & Isolation Agent",
        "role": "Tailscale-Only Architecture",
        "focus": "Evaluates the security model of zero public exposure via Tailscale + localhost bindings. Assesses Tailscale identity header trust, SSH key management, Telegram bot token security, the risk of misconfigured service bindings (0.0.0.0 instead of 127.0.0.1), and the Pincer audit's effectiveness as a pre-deploy check.",
        "evaluation_criteria": [
          "Tailscale identity header spoofing risk (can Dashboard/Control UI auth be bypassed)",
          "Service binding enforcement (how reliable is Pincer audit, post-deployment drift)",
          "Credential exposure surface (Telegram bot token, GitHub PAT, Coolify, OpenClaw config)",
          "Insider threat model (what if Tailscale account is compromised)",
          "Auditability & intrusion detection (logging, anomaly detection for unauthorized access)"
        ]
      }
    ],
    "council_progress": {
      "started_at": "2026-02-12T13:43:21.154Z",
      "agents": [
        {
          "agent_name": "Self-Hosting Infrastructure Agent",
          "status": "completed",
          "started_at": "2026-02-12T13:43:21.171Z",
          "completed_at": "2026-02-12T13:44:35.111Z",
          "evaluation": {
            "agent_name": "Self-Hosting Infrastructure Agent",
            "score": 5,
            "reasoning": "Single-VPS viability assessment based on infrastructure analysis:\n\n**Resource Adequacy (Concerning):** The stack runs 11+ services on one VPS: OpenClaw Gateway, Control UI, Dashboard, Coolify, mem0, Qdrant, multiple Docker containers, Auto-Claude, and host services. Minimum viable configuration requires 8GB RAM (OpenClaw ~500MB, Coolify base ~1GB, Qdrant 2-4GB for vectors, mem0 ~500MB, Dashboard ~300MB, OS/Docker ~2GB). During concurrent builds, Auto-Claude can spike to 1-2GB, and multiple AI Council sub-agents executing simultaneously will add memory pressure. A Hetzner 8GB VPS (~€20/mo) will struggle under load; 16GB (~€40/mo) is safer but still tight when running concurrent builds + vector searches + active agent sessions.\n\n**Backup/DR Strategy (Critical Gaps):** The PRD documents vault sync via Syncthing and code repos on GitHub—good. However, three critical gaps exist: (1) Qdrant vector database state for mem0 has NO backup strategy mentioned. Losing mem0's persistent memory defeats its purpose. (2) Docker volumes for Coolify deployments and other stateful services lack documented backup. (3) No disaster recovery runbook—if the VPS fails, recovery depends on manual Docker Compose restore, which could take hours and risks data loss. Hetzner snapshots are mentioned once but not formalized into a schedule or tested recovery procedure.\n\n**Operational Complexity (High Burden):** Managing 11 interdependent services on one machine creates a debugging nightmare. A failure in Qdrant breaks mem0; mem0 failure degrades OpenClaw; Tailscale issues block all access. The dependency chain (Tailscale → Gateway → mem0 → OpenClaw → Auto-Claude → Coolify → Dashboard) means troubleshooting requires deep knowledge across networking, Docker, AI agents, and custom tooling. Upgrade coordination is manual—no staging environment mentioned. The security checklist has 13 pre-deploy gates, but ongoing maintenance (patching Docker, updating OpenClaw, Coolify upgrades) adds continuous overhead for a personal system.\n\n**Cost-Benefit (Reasonable):** Hetzner 16GB VPS costs ~€40/mo ($528/year) vs. managed alternatives (Render/Railway/Fly.io) at $150-300/month. The 5-7x cost savings justify the complexity IF the user has sysadmin skills and accepts the operational burden. However, the PRD estimates $47-638/year in LLM API costs—hosting is 50-80% of total infrastructure spend, making the single-VPS savings less impactful than it first appears.\n\n**Failover & Redundancy (Single Point of Failure):** VPS failure = total system outage. No Telegram bot, no Dashboard, all builds lost, no agent access. Hetzner's ~99.9% uptime SLA means ~8-9 hours expected downtime per year. Recovery requires: VPS reboot → Docker Compose up → service health checks → Tailscale reconnection, estimated 10-30 minutes IF automated, hours if manual intervention needed. The PRD lacks monitoring/alerting—user might not know the system is down until they try to use it. Work-in-progress builds via Auto-Claude are lost on crash unless checkpointed to git.\n\n**Conclusion:** This architecture is *viable* for a technically skilled user who accepts high operational burden and periodic outages. It's NOT suitable for mission-critical workflows or users expecting cloud-like reliability. The lack of tested DR procedures and mem0 backup strategy are blocking concerns.",
            "concerns": [
              "Qdrant vector database (mem0 persistent memory) has no documented backup strategy—data loss on VPS failure",
              "8GB RAM insufficient for concurrent builds + AI Council + vector search; 16GB minimum recommended",
              "Docker volume backups not mentioned—Coolify deployment state at risk",
              "No disaster recovery runbook or tested restore procedure—recovery time unknown",
              "11 interdependent services create complex debugging and single points of failure throughout the stack",
              "No monitoring/alerting mentioned—user may not know system is down",
              "Auto-Claude builds lost on VPS crash unless frequently committed to git",
              "VPS failure = complete system outage (no Telegram, no Dashboard, no agents)",
              "Upgrade coordination across 11 services with no staging environment risks production breakage",
              "Hetzner ~99.9% SLA = ~8-9 hours expected downtime/year with manual recovery"
            ]
          }
        },
        {
          "agent_name": "AI Orchestration & Cost Agent",
          "status": "completed",
          "started_at": "2026-02-12T13:43:21.189Z",
          "completed_at": "2026-02-12T13:44:23.814Z",
          "evaluation": {
            "agent_name": "AI Orchestration & Cost Agent",
            "score": 3,
            "reasoning": "The architecture presents severe economic and orchestration sustainability concerns:\n\n**Cost Projections (Critical Issue):** The estimated daily costs ($0.13-$1.75) are fantasy numbers for this workload. Each idea traverses an 8-step pipeline with 4 Council sub-agents (each running full evals), 6 Auto-Claude phases (Spec→Plan→Code→QA→Fix), and Gemini Stitch calls. A single idea-to-deployment could easily consume 500K-2M tokens across all phases. At Claude Sonnet 4.5 rates (~$3/M input, $15/M output), a SINGLE project build could cost $15-50. Processing 5-10 ideas per week would run $300-500/month minimum, likely much higher with iteration loops.\n\n**Context Redundancy (Structural Flaw):** Three overlapping memory systems (Beads per-project, mem0 personal, Obsidian vault) with no deduplication strategy creates token waste. Every agent call must hydrate context from multiple sources. Beads and mem0 both \"index from vault\" but no clear separation of concerns—project decisions could live in both. Context loading overhead could add 20-50K tokens per agent invocation.\n\n**Vendor Lock-in (Existential Risk):** 100% dependency on Anthropic for core intelligence with NO fallback. OpenClaw, Auto-Claude, and all Council agents require Claude API. Single API key compromise, rate limit hit, or Anthropic pricing change breaks the entire system. The mention of \"GPT-5 mini\" and \"GPT-5\" (which don't exist) reveals wishful thinking, not actual multi-provider strategy.\n\n**Diminishing Returns (Already Exceeded):** For a PERSONAL productivity system, running 10+ AI agent calls per idea is absurd overhead. A human + single Claude session could spec and validate faster and cheaper. The AI Council validation (4 agents debating technical feasibility, personal alignment, and impact) adds 4x token cost for marginal value—a single thoughtful prompt to one model would suffice.\n\n**Fallback Strategies (Nonexistent):** Despite listing \"degraded operation if AI services unavailable\" as a risk, the PRD provides ZERO mitigation. No offline mode, no cached fallbacks, no alternative models configured. The system is binary: full AI orchestration or nothing. \"Pin versions\" doesn't help during Anthropic outages.\n\n**The Real Problem:** This is AI complexity theater—using agentic workflows because they're trendy, not because they solve a real problem. A personal productivity system should start simple (Telegram→OpenClaw→Vault) and add AI orchestration only where it delivers 10x value. This design inverts that: maximum AI complexity from day one, with costs and fragility that guarantee abandonment within 2-3 months when the bill hits $500+ and the first Anthropic rate limit breaks the workflow.",
            "concerns": [
              "Actual monthly costs likely $300-500+ for moderate use (5-10 projects/month), not the $3.90-$31.50 implied by daily estimates",
              "No multi-provider fallback—100% Anthropic lock-in creates single point of failure for entire system",
              "Three-layer memory architecture (Beads + mem0 + Vault) causes context bloat and redundancy without clear deduplication",
              "AI Council (4 agents per idea) and Auto-Claude (6 phases per build) create 10-30x token overhead vs. single-model approach",
              "Zero fallback strategy for API outages, rate limits, or service degradation despite acknowledging risk",
              "Prompt caching savings assumed but not validated—complex multi-agent flows often break cache efficiency",
              "Cost projections use non-existent models (GPT-5) indicating lack of real pricing research",
              "Diminishing returns already exceeded: personal productivity doesn't justify 10+ AI calls per idea validation"
            ]
          }
        },
        {
          "agent_name": "Autonomous Development Safety Agent",
          "status": "completed",
          "started_at": "2026-02-12T13:43:21.202Z",
          "completed_at": "2026-02-12T13:44:36.737Z",
          "evaluation": {
            "agent_name": "Autonomous Development Safety Agent",
            "score": 3,
            "reasoning": "The autonomous code generation and deployment pipeline has severe structural vulnerabilities that cannot be mitigated by the documented controls. The core flaw is circular: Auto-Claude writes code, Auto-Claude writes tests for that code, Auto-Claude reviews the code, and a non-expert human is expected to catch what the AI missed—this is security theater, not security. The single-VPS architecture means a container escape or resource exhaustion attack affects all services. No static analysis, secret scanning, or independent validation gates exist. The 'review step' creates a false sense of safety while being functionally unauditable for most users. Rollback mechanisms are undefined for stateful applications. The blast radius is maximized by co-locating all apps, services, and the knowledge base on one machine with shared Docker infrastructure. This architecture optimizes for convenience and autonomy at the expense of defense in depth.",
            "concerns": [
              "Self-review loop: Auto-Claude generates code, tests, and QA reviews—no independent validation",
              "Human review bottleneck is illusory: non-experts cannot meaningfully audit AI-generated codebases under time pressure",
              "No static analysis, secret scanning, or dependency vulnerability checks in the pipeline",
              "Single VPS = maximized blast radius: one malicious app can compromise entire system via container escape",
              "No staging environment: testing and production share infrastructure",
              "Database and stateful rollback strategy completely undefined",
              "Docker sandbox helps but doesn't prevent malicious code from running post-deployment",
              "Resource limits not mentioned: auto-generated app could DOS the entire VPS",
              "Spec-kit and Stitch outputs are trusted inputs but could be manipulated via prompt injection in earlier stages",
              "No security testing (SAST/DAST) or penetration testing in the pipeline",
              "Test quality depends entirely on Auto-Claude's competence—no coverage requirements or independent test generation",
              "Coolify deployment lacks canary/blue-green strategies for safe production rollout"
            ]
          }
        },
        {
          "agent_name": "Personal Workflow Adoption Agent",
          "status": "completed",
          "started_at": "2026-02-12T13:43:21.211Z",
          "completed_at": "2026-02-12T13:44:16.128Z",
          "evaluation": {
            "agent_name": "Personal Workflow Adoption Agent",
            "score": 3,
            "reasoning": "Focus Flow OS presents severe cognitive load challenges that will likely prevent most users from successfully adopting it. The onboarding complexity is extreme: 12+ interconnected tools, 13-week phased implementation, VPS/Docker/Tailscale infrastructure knowledge required, and a 13-item security checklist that blocks deployment. Value activation time is 10-12 weeks minimum before the first idea becomes a deployed app. Daily friction is high: dual interfaces (Telegram + Dashboard) fragment attention, multiple notification sources create alert fatigue, and every build requires manual review in step 7. Decision fatigue is significant—AI Council recommendations need user approval, classification errors need correction, and approval workflows exist at capture, validation, review, and deploy stages. The vault structure (6 top-level folders, nested per-project folders with .specify/, designs/, decisions/) requires constant mental mapping. The PRD itself acknowledges the 'inbox junk drawer' risk. Most critically: this system assumes the user will maintain motivation through 6 weeks of infrastructure work before seeing any end-to-end value. Research on habit formation and tool adoption shows this violates the 'time-to-first-value' principle—users need wins within days, not months. The system is built for the 1% who are infrastructure engineers AND productivity enthusiasts. For personal use, the overhead-to-value ratio is inverted.",
            "concerns": [
              "10-12 week value activation time violates rapid feedback loops needed for habit formation",
              "Dual-interface design (Telegram + Dashboard) creates systematic context-switching overhead",
              "AI Council approval workflow at step 3 + manual review at step 7 = two friction points per idea",
              "Vault organization (00_inbox/, 01_daily/, 02_projects/{p}/.specify/specs/) requires持续mental model maintenance",
              "Notification fatigue: Telegram responses + Dashboard approvals queue + Council verdicts + build status updates",
              "Onboarding assumes expertise in: VPS, Docker, Tailscale, Obsidian, Claude Code CLI, GitHub, shell scripting",
              "First 6 weeks (Phases 0-2) are pure infrastructure with zero workflow value",
              "Syncthing vault conflicts require manual resolution—additional maintenance burden",
              "Security checklist (13 items) creates deployment anxiety for non-DevOps users",
              "System breaks if any single tool fails (OpenClaw, Coolify, mem0, Auto-Claude)—cascading cognitive load during debugging"
            ]
          }
        },
        {
          "agent_name": "Network Security & Isolation Agent",
          "status": "completed",
          "started_at": "2026-02-12T13:43:21.230Z",
          "completed_at": "2026-02-12T13:45:36.505Z",
          "evaluation": {
            "agent_name": "Network Security & Isolation Agent",
            "score": 4,
            "reasoning": "The Tailscale-only model provides strong perimeter defense (zero public exposure, localhost binding) but has critical gaps in defense-in-depth, monitoring, and credential management that create severe risks if the outer layer fails.\n\n**1. Tailscale Identity Header Risk (CRITICAL):** The PRD states headers are 'primary authentication' for Dashboard/Control UI but provides no implementation detail. The PRD itself lists 'Localhost trust bypass via reverse proxies' as a documented vulnerability, with 'trustedProxies configuration' as mitigation—but never explains HOW this is configured or validated. If trustedProxies is misconfigured, an attacker who gains ANY network access (compromised container, supply chain attack in a dependency) can forge headers. No mention of additional auth layers, MFA, or session validation beyond the header.\n\n**2. Service Binding Enforcement (MAJOR FLAW):** Pincer is a pre-deploy one-time check with ZERO post-deployment monitoring. Services restart after updates (explicit: Coolify auto-deploy, OpenClaw updates via gateway restart). Default Docker Compose behavior often binds 0.0.0.0 unless explicitly overridden per service. The security checklist (#9: 'No services exposed on 0.0.0.0') requires manual 'ss -tlnp check' but is not continuous. Post-deployment drift is the EXACT failure mode, and there's no mitigation—just hope services don't change bindings.\n\n**3. Credential Exposure (HIGH RISK):** The PRD lists at least 6 high-value credentials (Telegram bot, GitHub PAT, Claude API, Coolify, mem0, Tailscale itself) stored as 'environment variables or secrets manager'—but never specifies which, how they're rotated, or access controls. Coolify mounts /var/run/docker.sock (explicit in docker-compose.yml), which is root-equivalent access—any Coolify compromise = instant host root. Auto-Claude runs on HOST (not in Docker despite 'sandbox recommendation'), with direct filesystem access to /srv/projects/ and /srv/vault/. A single compromised credential (e.g., leaked Telegram bot token) grants full impersonation with no secondary verification mentioned.\n\n**4. Insider Threat / Tailscale Compromise (CATASTROPHIC SINGLE POINT OF FAILURE):** If the Tailscale account is compromised (phishing, credential stuffing, session hijacking), the attacker joins the tailnet and the entire security model collapses. All services trust Tailscale identity headers with no additional auth layers, no rate limiting, no geo-fencing, no device posture checks mentioned. The PRD has no defense-in-depth: it's 'trust Tailscale or nothing.'\n\n**5. Auditability & Intrusion Detection (NON-EXISTENT):** The PRD mentions ZERO logging, monitoring, or alerting infrastructure. No audit logs for Dashboard access, no anomaly detection (e.g., unusual API usage patterns, off-hours access), no intrusion detection, no SIEM. OpenClaw session logs exist (~/.openclaw/sessions/*.jsonl) but no analysis or alerting. An attacker who gains access operates undetected until manual discovery.\n\n**Mitigating Strengths:** The zero-public-exposure architecture (all services on 127.0.0.1, UFW deny-all, Tailscale-only SSH) eliminates the most common attack vector (internet-facing vulns). The explicit ClawHub ban shows supply-chain awareness. The security checklist (12 items pre-deploy) is more than most hobbyist projects attempt.\n\n**Fatal Weaknesses:** No defense-in-depth, no continuous monitoring, Coolify has root-equivalent Docker socket access, Auto-Claude runs unsandboxed on host, Tailscale compromise = total loss, and credential management is vague. The architecture assumes Tailscale never fails—but security models that rely on a single control plane with no fallback are fragile.",
            "concerns": [
              "Tailscale identity headers as sole auth with no implementation detail, MFA, or session validation—'trustedProxies configuration' mentioned but never defined",
              "Pincer pre-deploy check is one-time only; no continuous monitoring for service binding drift after updates/restarts (Coolify auto-deploy, OpenClaw gateway restart explicit in workflow)",
              "Coolify mounts /var/run/docker.sock (root-equivalent access); any Coolify compromise = instant container escape to host root",
              "Auto-Claude runs on HOST (not Docker sandbox despite PRD acknowledging sandbox recommendation), with direct access to /srv/projects/ and /srv/vault/—can modify system files",
              "Six high-value credentials (Telegram bot token, GitHub PAT, Claude API, Coolify, mem0, Tailscale) stored as 'environment variables or secrets manager' with no rotation strategy, access controls, or secrets manager specified",
              "Tailscale account compromise = catastrophic single point of failure; attacker joins tailnet, all services trust identity headers, no additional auth layers or device posture checks",
              "Zero logging, monitoring, or alerting infrastructure—no audit logs, anomaly detection, intrusion detection, or SIEM; attackers operate undetected",
              "Single VPS architecture: all services, vault, code, credentials, AI session history on one machine with no network segmentation—total loss if VPS compromised",
              "Telegram bot token leak enables full impersonation; dmPolicy: pairing helps but no rate limiting, secondary auth, or message authenticity verification beyond Telegram's layer",
              "No incident response plan, no backup auth method if Tailscale is down, no key revocation procedure—operational security gaps alongside technical ones"
            ]
          }
        }
      ],
      "synthesis_status": "completed",
      "completed_count": 5,
      "total_count": 5
    },
    "council_verdict": {
      "recommendation": "reject",
      "overall_score": 3.6,
      "evaluations": [
        {
          "agent_name": "Self-Hosting Infrastructure Agent",
          "score": 5,
          "reasoning": "Single-VPS viability assessment based on infrastructure analysis:\n\n**Resource Adequacy (Concerning):** The stack runs 11+ services on one VPS: OpenClaw Gateway, Control UI, Dashboard, Coolify, mem0, Qdrant, multiple Docker containers, Auto-Claude, and host services. Minimum viable configuration requires 8GB RAM (OpenClaw ~500MB, Coolify base ~1GB, Qdrant 2-4GB for vectors, mem0 ~500MB, Dashboard ~300MB, OS/Docker ~2GB). During concurrent builds, Auto-Claude can spike to 1-2GB, and multiple AI Council sub-agents executing simultaneously will add memory pressure. A Hetzner 8GB VPS (~€20/mo) will struggle under load; 16GB (~€40/mo) is safer but still tight when running concurrent builds + vector searches + active agent sessions.\n\n**Backup/DR Strategy (Critical Gaps):** The PRD documents vault sync via Syncthing and code repos on GitHub—good. However, three critical gaps exist: (1) Qdrant vector database state for mem0 has NO backup strategy mentioned. Losing mem0's persistent memory defeats its purpose. (2) Docker volumes for Coolify deployments and other stateful services lack documented backup. (3) No disaster recovery runbook—if the VPS fails, recovery depends on manual Docker Compose restore, which could take hours and risks data loss. Hetzner snapshots are mentioned once but not formalized into a schedule or tested recovery procedure.\n\n**Operational Complexity (High Burden):** Managing 11 interdependent services on one machine creates a debugging nightmare. A failure in Qdrant breaks mem0; mem0 failure degrades OpenClaw; Tailscale issues block all access. The dependency chain (Tailscale → Gateway → mem0 → OpenClaw → Auto-Claude → Coolify → Dashboard) means troubleshooting requires deep knowledge across networking, Docker, AI agents, and custom tooling. Upgrade coordination is manual—no staging environment mentioned. The security checklist has 13 pre-deploy gates, but ongoing maintenance (patching Docker, updating OpenClaw, Coolify upgrades) adds continuous overhead for a personal system.\n\n**Cost-Benefit (Reasonable):** Hetzner 16GB VPS costs ~€40/mo ($528/year) vs. managed alternatives (Render/Railway/Fly.io) at $150-300/month. The 5-7x cost savings justify the complexity IF the user has sysadmin skills and accepts the operational burden. However, the PRD estimates $47-638/year in LLM API costs—hosting is 50-80% of total infrastructure spend, making the single-VPS savings less impactful than it first appears.\n\n**Failover & Redundancy (Single Point of Failure):** VPS failure = total system outage. No Telegram bot, no Dashboard, all builds lost, no agent access. Hetzner's ~99.9% uptime SLA means ~8-9 hours expected downtime per year. Recovery requires: VPS reboot → Docker Compose up → service health checks → Tailscale reconnection, estimated 10-30 minutes IF automated, hours if manual intervention needed. The PRD lacks monitoring/alerting—user might not know the system is down until they try to use it. Work-in-progress builds via Auto-Claude are lost on crash unless checkpointed to git.\n\n**Conclusion:** This architecture is *viable* for a technically skilled user who accepts high operational burden and periodic outages. It's NOT suitable for mission-critical workflows or users expecting cloud-like reliability. The lack of tested DR procedures and mem0 backup strategy are blocking concerns.",
          "concerns": [
            "Qdrant vector database (mem0 persistent memory) has no documented backup strategy—data loss on VPS failure",
            "8GB RAM insufficient for concurrent builds + AI Council + vector search; 16GB minimum recommended",
            "Docker volume backups not mentioned—Coolify deployment state at risk",
            "No disaster recovery runbook or tested restore procedure—recovery time unknown",
            "11 interdependent services create complex debugging and single points of failure throughout the stack",
            "No monitoring/alerting mentioned—user may not know system is down",
            "Auto-Claude builds lost on VPS crash unless frequently committed to git",
            "VPS failure = complete system outage (no Telegram, no Dashboard, no agents)",
            "Upgrade coordination across 11 services with no staging environment risks production breakage",
            "Hetzner ~99.9% SLA = ~8-9 hours expected downtime/year with manual recovery"
          ]
        },
        {
          "agent_name": "AI Orchestration & Cost Agent",
          "score": 3,
          "reasoning": "The architecture presents severe economic and orchestration sustainability concerns:\n\n**Cost Projections (Critical Issue):** The estimated daily costs ($0.13-$1.75) are fantasy numbers for this workload. Each idea traverses an 8-step pipeline with 4 Council sub-agents (each running full evals), 6 Auto-Claude phases (Spec→Plan→Code→QA→Fix), and Gemini Stitch calls. A single idea-to-deployment could easily consume 500K-2M tokens across all phases. At Claude Sonnet 4.5 rates (~$3/M input, $15/M output), a SINGLE project build could cost $15-50. Processing 5-10 ideas per week would run $300-500/month minimum, likely much higher with iteration loops.\n\n**Context Redundancy (Structural Flaw):** Three overlapping memory systems (Beads per-project, mem0 personal, Obsidian vault) with no deduplication strategy creates token waste. Every agent call must hydrate context from multiple sources. Beads and mem0 both \"index from vault\" but no clear separation of concerns—project decisions could live in both. Context loading overhead could add 20-50K tokens per agent invocation.\n\n**Vendor Lock-in (Existential Risk):** 100% dependency on Anthropic for core intelligence with NO fallback. OpenClaw, Auto-Claude, and all Council agents require Claude API. Single API key compromise, rate limit hit, or Anthropic pricing change breaks the entire system. The mention of \"GPT-5 mini\" and \"GPT-5\" (which don't exist) reveals wishful thinking, not actual multi-provider strategy.\n\n**Diminishing Returns (Already Exceeded):** For a PERSONAL productivity system, running 10+ AI agent calls per idea is absurd overhead. A human + single Claude session could spec and validate faster and cheaper. The AI Council validation (4 agents debating technical feasibility, personal alignment, and impact) adds 4x token cost for marginal value—a single thoughtful prompt to one model would suffice.\n\n**Fallback Strategies (Nonexistent):** Despite listing \"degraded operation if AI services unavailable\" as a risk, the PRD provides ZERO mitigation. No offline mode, no cached fallbacks, no alternative models configured. The system is binary: full AI orchestration or nothing. \"Pin versions\" doesn't help during Anthropic outages.\n\n**The Real Problem:** This is AI complexity theater—using agentic workflows because they're trendy, not because they solve a real problem. A personal productivity system should start simple (Telegram→OpenClaw→Vault) and add AI orchestration only where it delivers 10x value. This design inverts that: maximum AI complexity from day one, with costs and fragility that guarantee abandonment within 2-3 months when the bill hits $500+ and the first Anthropic rate limit breaks the workflow.",
          "concerns": [
            "Actual monthly costs likely $300-500+ for moderate use (5-10 projects/month), not the $3.90-$31.50 implied by daily estimates",
            "No multi-provider fallback—100% Anthropic lock-in creates single point of failure for entire system",
            "Three-layer memory architecture (Beads + mem0 + Vault) causes context bloat and redundancy without clear deduplication",
            "AI Council (4 agents per idea) and Auto-Claude (6 phases per build) create 10-30x token overhead vs. single-model approach",
            "Zero fallback strategy for API outages, rate limits, or service degradation despite acknowledging risk",
            "Prompt caching savings assumed but not validated—complex multi-agent flows often break cache efficiency",
            "Cost projections use non-existent models (GPT-5) indicating lack of real pricing research",
            "Diminishing returns already exceeded: personal productivity doesn't justify 10+ AI calls per idea validation"
          ]
        },
        {
          "agent_name": "Autonomous Development Safety Agent",
          "score": 3,
          "reasoning": "The autonomous code generation and deployment pipeline has severe structural vulnerabilities that cannot be mitigated by the documented controls. The core flaw is circular: Auto-Claude writes code, Auto-Claude writes tests for that code, Auto-Claude reviews the code, and a non-expert human is expected to catch what the AI missed—this is security theater, not security. The single-VPS architecture means a container escape or resource exhaustion attack affects all services. No static analysis, secret scanning, or independent validation gates exist. The 'review step' creates a false sense of safety while being functionally unauditable for most users. Rollback mechanisms are undefined for stateful applications. The blast radius is maximized by co-locating all apps, services, and the knowledge base on one machine with shared Docker infrastructure. This architecture optimizes for convenience and autonomy at the expense of defense in depth.",
          "concerns": [
            "Self-review loop: Auto-Claude generates code, tests, and QA reviews—no independent validation",
            "Human review bottleneck is illusory: non-experts cannot meaningfully audit AI-generated codebases under time pressure",
            "No static analysis, secret scanning, or dependency vulnerability checks in the pipeline",
            "Single VPS = maximized blast radius: one malicious app can compromise entire system via container escape",
            "No staging environment: testing and production share infrastructure",
            "Database and stateful rollback strategy completely undefined",
            "Docker sandbox helps but doesn't prevent malicious code from running post-deployment",
            "Resource limits not mentioned: auto-generated app could DOS the entire VPS",
            "Spec-kit and Stitch outputs are trusted inputs but could be manipulated via prompt injection in earlier stages",
            "No security testing (SAST/DAST) or penetration testing in the pipeline",
            "Test quality depends entirely on Auto-Claude's competence—no coverage requirements or independent test generation",
            "Coolify deployment lacks canary/blue-green strategies for safe production rollout"
          ]
        },
        {
          "agent_name": "Personal Workflow Adoption Agent",
          "score": 3,
          "reasoning": "Focus Flow OS presents severe cognitive load challenges that will likely prevent most users from successfully adopting it. The onboarding complexity is extreme: 12+ interconnected tools, 13-week phased implementation, VPS/Docker/Tailscale infrastructure knowledge required, and a 13-item security checklist that blocks deployment. Value activation time is 10-12 weeks minimum before the first idea becomes a deployed app. Daily friction is high: dual interfaces (Telegram + Dashboard) fragment attention, multiple notification sources create alert fatigue, and every build requires manual review in step 7. Decision fatigue is significant—AI Council recommendations need user approval, classification errors need correction, and approval workflows exist at capture, validation, review, and deploy stages. The vault structure (6 top-level folders, nested per-project folders with .specify/, designs/, decisions/) requires constant mental mapping. The PRD itself acknowledges the 'inbox junk drawer' risk. Most critically: this system assumes the user will maintain motivation through 6 weeks of infrastructure work before seeing any end-to-end value. Research on habit formation and tool adoption shows this violates the 'time-to-first-value' principle—users need wins within days, not months. The system is built for the 1% who are infrastructure engineers AND productivity enthusiasts. For personal use, the overhead-to-value ratio is inverted.",
          "concerns": [
            "10-12 week value activation time violates rapid feedback loops needed for habit formation",
            "Dual-interface design (Telegram + Dashboard) creates systematic context-switching overhead",
            "AI Council approval workflow at step 3 + manual review at step 7 = two friction points per idea",
            "Vault organization (00_inbox/, 01_daily/, 02_projects/{p}/.specify/specs/) requires持续mental model maintenance",
            "Notification fatigue: Telegram responses + Dashboard approvals queue + Council verdicts + build status updates",
            "Onboarding assumes expertise in: VPS, Docker, Tailscale, Obsidian, Claude Code CLI, GitHub, shell scripting",
            "First 6 weeks (Phases 0-2) are pure infrastructure with zero workflow value",
            "Syncthing vault conflicts require manual resolution—additional maintenance burden",
            "Security checklist (13 items) creates deployment anxiety for non-DevOps users",
            "System breaks if any single tool fails (OpenClaw, Coolify, mem0, Auto-Claude)—cascading cognitive load during debugging"
          ]
        },
        {
          "agent_name": "Network Security & Isolation Agent",
          "score": 4,
          "reasoning": "The Tailscale-only model provides strong perimeter defense (zero public exposure, localhost binding) but has critical gaps in defense-in-depth, monitoring, and credential management that create severe risks if the outer layer fails.\n\n**1. Tailscale Identity Header Risk (CRITICAL):** The PRD states headers are 'primary authentication' for Dashboard/Control UI but provides no implementation detail. The PRD itself lists 'Localhost trust bypass via reverse proxies' as a documented vulnerability, with 'trustedProxies configuration' as mitigation—but never explains HOW this is configured or validated. If trustedProxies is misconfigured, an attacker who gains ANY network access (compromised container, supply chain attack in a dependency) can forge headers. No mention of additional auth layers, MFA, or session validation beyond the header.\n\n**2. Service Binding Enforcement (MAJOR FLAW):** Pincer is a pre-deploy one-time check with ZERO post-deployment monitoring. Services restart after updates (explicit: Coolify auto-deploy, OpenClaw updates via gateway restart). Default Docker Compose behavior often binds 0.0.0.0 unless explicitly overridden per service. The security checklist (#9: 'No services exposed on 0.0.0.0') requires manual 'ss -tlnp check' but is not continuous. Post-deployment drift is the EXACT failure mode, and there's no mitigation—just hope services don't change bindings.\n\n**3. Credential Exposure (HIGH RISK):** The PRD lists at least 6 high-value credentials (Telegram bot, GitHub PAT, Claude API, Coolify, mem0, Tailscale itself) stored as 'environment variables or secrets manager'—but never specifies which, how they're rotated, or access controls. Coolify mounts /var/run/docker.sock (explicit in docker-compose.yml), which is root-equivalent access—any Coolify compromise = instant host root. Auto-Claude runs on HOST (not in Docker despite 'sandbox recommendation'), with direct filesystem access to /srv/projects/ and /srv/vault/. A single compromised credential (e.g., leaked Telegram bot token) grants full impersonation with no secondary verification mentioned.\n\n**4. Insider Threat / Tailscale Compromise (CATASTROPHIC SINGLE POINT OF FAILURE):** If the Tailscale account is compromised (phishing, credential stuffing, session hijacking), the attacker joins the tailnet and the entire security model collapses. All services trust Tailscale identity headers with no additional auth layers, no rate limiting, no geo-fencing, no device posture checks mentioned. The PRD has no defense-in-depth: it's 'trust Tailscale or nothing.'\n\n**5. Auditability & Intrusion Detection (NON-EXISTENT):** The PRD mentions ZERO logging, monitoring, or alerting infrastructure. No audit logs for Dashboard access, no anomaly detection (e.g., unusual API usage patterns, off-hours access), no intrusion detection, no SIEM. OpenClaw session logs exist (~/.openclaw/sessions/*.jsonl) but no analysis or alerting. An attacker who gains access operates undetected until manual discovery.\n\n**Mitigating Strengths:** The zero-public-exposure architecture (all services on 127.0.0.1, UFW deny-all, Tailscale-only SSH) eliminates the most common attack vector (internet-facing vulns). The explicit ClawHub ban shows supply-chain awareness. The security checklist (12 items pre-deploy) is more than most hobbyist projects attempt.\n\n**Fatal Weaknesses:** No defense-in-depth, no continuous monitoring, Coolify has root-equivalent Docker socket access, Auto-Claude runs unsandboxed on host, Tailscale compromise = total loss, and credential management is vague. The architecture assumes Tailscale never fails—but security models that rely on a single control plane with no fallback are fragile.",
          "concerns": [
            "Tailscale identity headers as sole auth with no implementation detail, MFA, or session validation—'trustedProxies configuration' mentioned but never defined",
            "Pincer pre-deploy check is one-time only; no continuous monitoring for service binding drift after updates/restarts (Coolify auto-deploy, OpenClaw gateway restart explicit in workflow)",
            "Coolify mounts /var/run/docker.sock (root-equivalent access); any Coolify compromise = instant container escape to host root",
            "Auto-Claude runs on HOST (not Docker sandbox despite PRD acknowledging sandbox recommendation), with direct access to /srv/projects/ and /srv/vault/—can modify system files",
            "Six high-value credentials (Telegram bot token, GitHub PAT, Claude API, Coolify, mem0, Tailscale) stored as 'environment variables or secrets manager' with no rotation strategy, access controls, or secrets manager specified",
            "Tailscale account compromise = catastrophic single point of failure; attacker joins tailnet, all services trust identity headers, no additional auth layers or device posture checks",
            "Zero logging, monitoring, or alerting infrastructure—no audit logs, anomaly detection, intrusion detection, or SIEM; attackers operate undetected",
            "Single VPS architecture: all services, vault, code, credentials, AI session history on one machine with no network segmentation—total loss if VPS compromised",
            "Telegram bot token leak enables full impersonation; dmPolicy: pairing helps but no rate limiting, secondary auth, or message authenticity verification beyond Telegram's layer",
            "No incident response plan, no backup auth method if Tailscale is down, no key revocation procedure—operational security gaps alongside technical ones"
          ]
        }
      ],
      "synthesized_reasoning": "Focus Flow OS demonstrates security awareness and architectural ambition but suffers from a fatal combination of over-engineering, operational fragility, and unrealistic viability projections. The core contradiction: it's designed as a personal productivity system yet requires enterprise-level infrastructure skills, 10-12 weeks to first value, and $300-500+/month in actual costs (vs. projected $5-30). The AI orchestration pipeline (4 Council agents + 6 Auto-Claude phases per idea) creates 10-30x token overhead with diminishing returns—a single Claude session would be faster and cheaper. The single-VPS architecture maximizes blast radius while lacking basic operational hygiene: no backup strategy for Qdrant/mem0, no monitoring/alerting, no tested disaster recovery. Security relies entirely on Tailscale (single point of failure) with no defense-in-depth—Coolify has root-equivalent Docker socket access, Auto-Claude runs unsandboxed on host, and credential management is undefined. The autonomous build pipeline is security theater: Auto-Claude writes code, tests, and reviews itself with human review as an illusory gate. Most critically, this violates adoption fundamentals: 6 weeks of infrastructure work before any workflow value, dual interfaces creating context-switching overhead, and cognitive load from 12+ interconnected tools. This is complexity for complexity's sake—a 1% solution (infrastructure engineer + productivity enthusiast) presented as universally applicable. The right system would start with Telegram→Claude→Obsidian and add automation only where it delivers 10x value. This inverts that principle.",
      "next_steps": [
        "Reject current architecture as non-viable for stated personal productivity use case",
        "If proceeding anyway, mandate these blocking changes: (1) Multi-VPS architecture with service separation, (2) Automated daily backups for Qdrant, mem0, and Docker volumes with tested restore procedure, (3) Monitoring/alerting (Prometheus + Grafana minimum), (4) Multi-provider AI strategy with fallback models, (5) Independent security validation in build pipeline (SAST/secret scanning), (6) Secondary auth beyond Tailscale headers",
        "Consider fundamental redesign: Start with MVP (Telegram→OpenClaw→Vault only), measure actual usage for 4 weeks, add ONE automation at a time based on demonstrated pain points—NOT theoretical workflows",
        "If building for learning/portfolio (not actual daily use), explicitly acknowledge this is a showcase project with high operational burden and frame expectations accordingly",
        "Conduct realistic cost modeling: Track actual token usage for 20 sample ideas through full pipeline before committing to architecture",
        "Address the adoption paradox: A system this complex requires discipline and motivation to maintain—but people needing that level of structure typically lack the bandwidth to build/maintain such systems"
      ],
      "council_composition": [
        "Self-Hosting Infrastructure Agent",
        "AI Orchestration & Cost Agent",
        "Autonomous Development Safety Agent",
        "Personal Workflow Adoption Agent",
        "Network Security & Isolation Agent"
      ]
    }
  }
}